{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harvey/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten,Conv2D,Conv1D,MaxPooling1D,  Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution1D,GlobalMaxPooling1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"C:/Users/Harvey/Desktop/Yelp_data_set/restuarant_review_5_label_unbalanced.csv\")\n",
    "df = pd.read_csv(\"/Users/harvey/Desktop/Data/restuarant_review_5_label_unbalanced.csv\")\n",
    "#df = pd.read_csv(\"/home/ec2-user/Data/restuarant_review_5_label_unbalanced.csv\")\n",
    "train = df.sample(frac = 0.8,random_state = 200)\n",
    "test = df.drop(train.index)\n",
    "train.loc[:,'stars'] -= 1\n",
    "print(np.unique(train['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train['Processed_Reviews'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(train['Processed_Reviews'])\n",
    "\n",
    "\n",
    "maxlen = 130\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "y = to_categorical(train['stars'])\n",
    "#####################\n",
    "# Test data\n",
    "tokenizer.fit_on_texts(test['Processed_Reviews'])\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(test['Processed_Reviews'])\n",
    "\n",
    "\n",
    "maxlen = 130\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "test.loc[:,'stars'] -=1\n",
    "y_test = test['stars']\n",
    "print(np.unique(test['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors in Glove 6B 100d.\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Using pretrained glove vector\n",
    "#####################################################################\n",
    "#GLOVE_DIR = \"/home/ec2-user/Data/\"\n",
    "GLOVE_DIR = \"/Users/harvey/Desktop/Data/\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'),encoding = 'utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embed_size = 100\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            embed_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=maxlen,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "#Test to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 130)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 130, 100)     27500700    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 128, 128)     38528       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 127, 128)     51328       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 126, 128)     64128       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 125, 128)     76928       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 128)     512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 127, 128)     512         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 126, 128)     512         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 125, 128)     512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 128)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 127, 128)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 126, 128)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 125, 128)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 128, 128)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 127, 128)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 126, 128)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 125, 128)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 32, 128)      0           dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 31, 128)      0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 31, 128)      0           dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 31, 128)      0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 125, 128)     0           max_pooling1d_5[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "                                                                 max_pooling1d_7[0][0]            \n",
      "                                                                 max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 125, 128)     0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 125, 256)     33024       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 125, 256)     1024        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 125, 256)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32000)        0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5)            160005      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,927,713\n",
      "Trainable params: 27,926,177\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n",
      "Train on 377894 samples, validate on 94474 samples\n",
      "Epoch 1/100\n",
      "  6656/377894 [..............................] - ETA: 27:44 - loss: 42.0762 - acc: 0.3026"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-23a38102306c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Randomly initialized \n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            embed_size,\n",
    "                            input_length=maxlen,\n",
    "                            trainable=True)\n",
    "\n",
    "\n",
    "#############################################\n",
    "# Original yoon kim with batch norm and drop out0\n",
    "#############################################\n",
    "conv_filters = 128\n",
    "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# Specify each convolution layer and their kernel siz i.e. n-grams \n",
    "conv1_1 = Conv1D(filters=conv_filters, kernel_size=3,kernel_regularizer=regularizers.l2(0.1))(embedded_sequences)\n",
    "btch1_1 = BatchNormalization()(conv1_1)\n",
    "actv1_1 = Activation('relu')(btch1_1)\n",
    "drp1_1  = Dropout(0.2)(actv1_1)\n",
    "glmp1_1 = MaxPooling1D(pool_size = 4)(drp1_1)\n",
    "#glmp1_1 = GlobalMaxPool1D()(drp1_1)\n",
    "\n",
    "conv1_2 = Conv1D(filters=conv_filters, kernel_size=4,kernel_regularizer=regularizers.l2(0.1))(embedded_sequences)\n",
    "btch1_2 = BatchNormalization()(conv1_2)\n",
    "actv1_2 = Activation('relu')(btch1_2)\n",
    "drp1_2  = Dropout(0.2)(actv1_2)\n",
    "glmp1_2 = MaxPooling1D(pool_size = 4)(drp1_2)\n",
    "#glmp1_2 =  GlobalMaxPool1D()(drp1_2)\n",
    "\n",
    "\n",
    "\n",
    "conv1_3 = Conv1D(filters=conv_filters, kernel_size=5,kernel_regularizer=regularizers.l2(0.1))(embedded_sequences)\n",
    "btch1_3 = BatchNormalization()(conv1_3)\n",
    "actv1_3 = Activation('relu')(btch1_3)\n",
    "drp1_3  = Dropout(0.2)(actv1_3)\n",
    "glmp1_3 = MaxPooling1D(pool_size = 4)(drp1_3)\n",
    "#glmp1_3 = GlobalMaxPool1D()(drp1_3)\n",
    "\n",
    "conv1_4 = Conv1D(filters=conv_filters, kernel_size=6,kernel_regularizer=regularizers.l2(0.1))(embedded_sequences)\n",
    "btch1_4 = BatchNormalization()(conv1_4)\n",
    "actv1_4 = Activation('relu')(btch1_4)\n",
    "drp1_4  = Dropout(0.2)(actv1_4)\n",
    "glmp1_4 = MaxPooling1D(pool_size = 4)(drp1_4)\n",
    "#glmp1_4 = GlobalMaxPool1D()(drp1_4)\n",
    "\n",
    "# Gather all convolution layers\n",
    "cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
    "drp1 = Dropout(0.2)(cnct)\n",
    "\n",
    "dns1  = Dense(256, activation='relu')(drp1)\n",
    "btch1 = BatchNormalization()(dns1)\n",
    "drp2  = Dropout(0.2)(btch1)\n",
    "flat = Flatten()(drp2)\n",
    "out = Dense(5, activation='softmax')(flat)\n",
    "\n",
    "\n",
    "model = Model(inputs=sequence_input, outputs=out)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "epochs = 100\n",
    "history = model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to be deleted\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 130, 100)          27500700  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 130, 50)           10050     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 255       \n",
      "=================================================================\n",
      "Total params: 27,511,005\n",
      "Trainable params: 10,305\n",
      "Non-trainable params: 27,500,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters = 50, kernel_size = 2, padding='same',activation = \"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 377894 samples, validate on 94474 samples\n",
      "Epoch 1/10\n",
      "377894/377894 [==============================] - 20s 52us/step - loss: 1.0487 - acc: 0.5503 - val_loss: 0.9574 - val_acc: 0.5866\n",
      "Epoch 2/10\n",
      "377894/377894 [==============================] - 18s 48us/step - loss: 0.9377 - acc: 0.5945 - val_loss: 0.9233 - val_acc: 0.5996\n",
      "Epoch 3/10\n",
      "377894/377894 [==============================] - 18s 48us/step - loss: 0.9121 - acc: 0.6041 - val_loss: 0.9144 - val_acc: 0.6029\n",
      "Epoch 4/10\n",
      "377894/377894 [==============================] - 18s 48us/step - loss: 0.8992 - acc: 0.6096 - val_loss: 0.9089 - val_acc: 0.6030\n",
      "Epoch 5/10\n",
      "377894/377894 [==============================] - 18s 48us/step - loss: 0.8911 - acc: 0.6122 - val_loss: 0.8974 - val_acc: 0.6108\n",
      "Epoch 6/10\n",
      "377894/377894 [==============================] - 18s 48us/step - loss: 0.8852 - acc: 0.6137 - val_loss: 0.9037 - val_acc: 0.6074\n",
      "Epoch 7/10\n",
      "377894/377894 [==============================] - 18s 48us/step - loss: 0.8797 - acc: 0.6160 - val_loss: 0.8961 - val_acc: 0.6100\n",
      "Epoch 8/10\n",
      "377894/377894 [==============================] - 18s 48us/step - loss: 0.8768 - acc: 0.6177 - val_loss: 0.9034 - val_acc: 0.6054\n",
      "Epoch 9/10\n",
      "377894/377894 [==============================] - 19s 49us/step - loss: 0.8725 - acc: 0.6188 - val_loss: 0.8924 - val_acc: 0.6120\n",
      "Epoch 10/10\n",
      "377894/377894 [==============================] - 18s 47us/step - loss: 0.8708 - acc: 0.6195 - val_loss: 0.8980 - val_acc: 0.6100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fbe015240>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4 3 4 3 0 3 3 2]\n",
      "(118092,)\n",
      "(118092,)\n",
      "accuracy :0.4749940724181147\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "y_pred = np.argmax(prediction,axis = 1)\n",
    "y_test = np.array(y_test)\n",
    "print(y_pred[:10])\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "print('accuracy :{0}'.format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            embed_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=maxlen,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Original yoon kim with batch norm and drop out0\n",
    "#############################################\n",
    "conv_filters = 128\n",
    "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# Specify each convolution layer and their kernel siz i.e. n-grams \n",
    "conv1_1 = Conv1D(filters=conv_filters, kernel_size=3)(embedded_sequences)\n",
    "btch1_1 = BatchNormalization()(conv1_1)\n",
    "actv1_1 = Activation('relu')(btch1_1)\n",
    "drp1_1  = Dropout(0.2)(actv1_1)\n",
    "glmp1_1 = GlobalMaxPooling1D()(drp1_1)\n",
    "\n",
    "conv1_2 = Conv1D(filters=conv_filters, kernel_size=4)(embedded_sequences)\n",
    "btch1_2 = BatchNormalization()(conv1_2)\n",
    "actv1_2 = Activation('relu')(btch1_2)\n",
    "drp1_2  = Dropout(0.2)(actv1_2)\n",
    "glmp1_2 = GlobalMaxPooling1D()(drp1_2)\n",
    "\n",
    "conv1_3 = Conv1D(filters=conv_filters, kernel_size=5)(embedded_sequences)\n",
    "btch1_3 = BatchNormalization()(conv1_3)\n",
    "actv1_3 = Activation('relu')(btch1_3)\n",
    "drp1_3  = Dropout(0.2)(actv1_3)\n",
    "glmp1_3 = GlobalMaxPooling1D()(drp1_3)\n",
    "\n",
    "conv1_4 = Conv1D(filters=conv_filters, kernel_size=6)(embedded_sequences)\n",
    "btch1_4 = BatchNormalization()(conv1_4)\n",
    "actv1_4 = Activation('relu')(btch1_4)\n",
    "drp1_4  = Dropout(0.2)(actv1_4)\n",
    "glmp1_4 = GlobalMaxPooling1D()(drp1_4)\n",
    "\n",
    "# Gather all convolution layers\n",
    "cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
    "drp1 = Dropout(0.2)(cnct)\n",
    "\n",
    "dns1  = Dense(32, activation='relu')(drp1)\n",
    "btch1 = BatchNormalization()(dns1)\n",
    "drp2  = Dropout(0.2)(btch1)\n",
    "\n",
    "out = Dense(5, activation='softmax')(drp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 130)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 130, 100)     27500700    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 128, 128)     38528       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 127, 128)     51328       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 126, 128)     64128       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 125, 128)     76928       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128)     512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 127, 128)     512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 126, 128)     512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 125, 128)     512         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 127, 128)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 126, 128)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 125, 128)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 127, 128)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 126, 128)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 125, 128)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 128)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           16416       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32)           128         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            165         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,750,369\n",
      "Trainable params: 248,581\n",
      "Non-trainable params: 27,501,788\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=sequence_input, outputs=out)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 377894 samples, validate on 94474 samples\n",
      "Epoch 1/10\n",
      "377894/377894 [==============================] - 127s 335us/step - loss: 1.0949 - acc: 0.5313 - val_loss: 0.9862 - val_acc: 0.5708\n",
      "Epoch 2/10\n",
      "377894/377894 [==============================] - 124s 327us/step - loss: 0.9723 - acc: 0.5818 - val_loss: 0.9225 - val_acc: 0.5969\n",
      "Epoch 3/10\n",
      "377894/377894 [==============================] - 124s 328us/step - loss: 0.9368 - acc: 0.5960 - val_loss: 0.8970 - val_acc: 0.6121\n",
      "Epoch 4/10\n",
      "377894/377894 [==============================] - 124s 327us/step - loss: 0.9153 - acc: 0.6051 - val_loss: 0.8880 - val_acc: 0.6111\n",
      "Epoch 5/10\n",
      "377894/377894 [==============================] - 124s 327us/step - loss: 0.9005 - acc: 0.6122 - val_loss: 0.8794 - val_acc: 0.6158\n",
      "Epoch 6/10\n",
      "377894/377894 [==============================] - 123s 325us/step - loss: 0.8871 - acc: 0.6177 - val_loss: 0.8638 - val_acc: 0.6261\n",
      "Epoch 7/10\n",
      "377894/377894 [==============================] - 123s 327us/step - loss: 0.8769 - acc: 0.6222 - val_loss: 0.8584 - val_acc: 0.6272\n",
      "Epoch 8/10\n",
      "377894/377894 [==============================] - 123s 326us/step - loss: 0.8674 - acc: 0.6259 - val_loss: 0.8555 - val_acc: 0.6280\n",
      "Epoch 9/10\n",
      "377894/377894 [==============================] - 124s 328us/step - loss: 0.8595 - acc: 0.6298 - val_loss: 0.8551 - val_acc: 0.6287\n",
      "Epoch 10/10\n",
      "377894/377894 [==============================] - 124s 329us/step - loss: 0.8533 - acc: 0.6323 - val_loss: 0.8481 - val_acc: 0.6300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f900b4710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 4 3 4 4 4 3 3 2]\n",
      "(118092,)\n",
      "(118092,)\n",
      "accuracy :0.5039206720184263\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "y_pred = np.argmax(prediction,axis = 1)\n",
    "y_test = np.array(y_test)\n",
    "print(y_pred[:10])\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "print('accuracy :{0}'.format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Orignal Yoon Kim \n",
    "##############################\n",
    "#############################################\n",
    "\n",
    "#############################################\n",
    "conv_filters = 128\n",
    "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "# Specify each convolution layer and their kernel siz i.e. n-grams \n",
    "conv1_1 = Conv1D(filters=conv_filters, kernel_size=3)(embedded_sequences)\n",
    "\n",
    "actv1_1 = Activation('relu')(conv1_1)\n",
    "glmp1_1 = GlobalMaxPooling1D()(actv1_1)\n",
    "\n",
    "conv1_2 = Conv1D(filters=conv_filters, kernel_size=4)(embedded_sequences)\n",
    "actv1_2 = Activation('relu')(conv1_2)\n",
    "glmp1_2 = GlobalMaxPooling1D()(actv1_2)\n",
    "\n",
    "conv1_3 = Conv1D(filters=conv_filters, kernel_size=5)(embedded_sequences)\n",
    "actv1_3 = Activation('relu')(conv1_3)\n",
    "glmp1_3 = GlobalMaxPooling1D()(actv1_3)\n",
    "\n",
    "conv1_4 = Conv1D(filters=conv_filters, kernel_size=6)(embedded_sequences)\n",
    "actv1_4 = Activation('relu')(conv1_4)\n",
    "glmp1_4 = GlobalMaxPooling1D()(actv1_4)\n",
    "\n",
    "# Gather all convolution layers\n",
    "cnct = concatenate([glmp1_1, glmp1_2, glmp1_3, glmp1_4], axis=1)\n",
    "\n",
    "dns1  = Dense(32, activation='relu')(cnct)\n",
    "drp2  = Dropout(0.5)(dns1)\n",
    "\n",
    "out = Dense(5, activation='softmax')(drp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 130)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 130, 100)     27500700    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 128, 128)     38528       embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 127, 128)     51328       embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 126, 128)     64128       embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 125, 128)     76928       embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 127, 128)     0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 126, 128)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 125, 128)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 128)          0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 128)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 128)          0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 128)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           global_max_pooling1d_6[0][0]     \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           16416       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 5)            165         dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,748,193\n",
      "Trainable params: 247,493\n",
      "Non-trainable params: 27,500,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=sequence_input, outputs=out)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 377894 samples, validate on 94474 samples\n",
      "Epoch 1/10\n",
      "377894/377894 [==============================] - 69s 183us/step - loss: 1.4620 - acc: 0.4017 - val_loss: 1.4494 - val_acc: 0.4002\n",
      "Epoch 2/10\n",
      "377894/377894 [==============================] - 68s 180us/step - loss: 1.4500 - acc: 0.4021 - val_loss: 1.4496 - val_acc: 0.4002\n",
      "Epoch 3/10\n",
      "377894/377894 [==============================] - 68s 181us/step - loss: 1.4499 - acc: 0.4020 - val_loss: 1.4494 - val_acc: 0.4002\n",
      "Epoch 4/10\n",
      "377894/377894 [==============================] - 68s 180us/step - loss: 1.4497 - acc: 0.4021 - val_loss: 1.4495 - val_acc: 0.4002\n",
      "Epoch 5/10\n",
      "377894/377894 [==============================] - 68s 180us/step - loss: 1.4497 - acc: 0.4021 - val_loss: 1.4494 - val_acc: 0.4002\n",
      "Epoch 6/10\n",
      "377894/377894 [==============================] - 68s 181us/step - loss: 1.4499 - acc: 0.4020 - val_loss: 1.4496 - val_acc: 0.4001\n",
      "Epoch 7/10\n",
      "377894/377894 [==============================] - 68s 180us/step - loss: 1.4498 - acc: 0.4020 - val_loss: 1.4496 - val_acc: 0.4002\n",
      "Epoch 8/10\n",
      "377894/377894 [==============================] - 68s 180us/step - loss: 1.4498 - acc: 0.4020 - val_loss: 1.4495 - val_acc: 0.4002\n",
      "Epoch 9/10\n",
      "377894/377894 [==============================] - 68s 181us/step - loss: 1.4108 - acc: 0.4175 - val_loss: 1.1839 - val_acc: 0.4990\n",
      "Epoch 10/10\n",
      "377894/377894 [==============================] - 68s 180us/step - loss: 1.2494 - acc: 0.4576 - val_loss: 1.1030 - val_acc: 0.4976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f02268a20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 4 4 4 4 4 4 4 0]\n",
      "(118092,)\n",
      "(118092,)\n",
      "accuracy :0.45113132134268197\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "y_pred = np.argmax(prediction,axis = 1)\n",
    "y_test = np.array(y_test)\n",
    "print(y_pred[:10])\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "print('accuracy :{0}'.format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
